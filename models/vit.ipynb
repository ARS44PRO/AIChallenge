{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Импорты\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib\n",
        "from pydub import AudioSegment\n",
        "import python_speech_features as psf\n",
        "from tensorflow.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import six\n",
        "import math\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, callbacks, models, callbacks\n",
        "from einops.layers.tensorflow import Rearrange\n",
        "\n",
        "%matplotlib inline\n",
        "logging.basicConfig(level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nPgcS8KkMAz"
      },
      "outputs": [],
      "source": [
        "# Константы\n",
        "DATA_PATH = '../new-data-without_silence'\n",
        "TRAIN_DATA_PATH = f'{DATA_PATH}/train'\n",
        "TASK_DATA_PATH = f'{DATA_PATH}/test'\n",
        "TRAIN_FILENAME = f'{DATA_PATH}/train_gt.csv'\n",
        "TASK_FILENAME = f'{DATA_PATH}/test.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igiJruf6kMA0",
        "outputId": "333919b7-6ae9-424c-92c0-8eb34f38d0ab"
      },
      "outputs": [],
      "source": [
        "# Загрзка данных\n",
        "df = pd.read_csv(TRAIN_FILENAME, header=None, names=['audio', 'label'])\n",
        "df['audio'] = TRAIN_DATA_PATH + \"/\" + df['audio']\n",
        "\n",
        "x, y = df['audio'], df['label'].to_numpy().reshape(-1, 1)\n",
        "\n",
        "weight_for_0 = (1 / (len(y) - np.sum(y))) * (len(y) / 2.0)\n",
        "weight_for_1 = (1 / np.sum(y)) * (len(y) / 2.0)\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "print(class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB16SNwlkMA1"
      },
      "outputs": [],
      "source": [
        "# # Обработка аудио\n",
        "\n",
        "# def preprocess_function(audio_path):\n",
        "#     segment = AudioSegment.from_mp3(audio_path)\n",
        "\n",
        "#     features, energy = psf.fbank(\n",
        "#         np.array(segment.get_array_of_samples()), segment.frame_rate\n",
        "#     )\n",
        "\n",
        "#     return features\n",
        "\n",
        "# features_list = []\n",
        "\n",
        "# for audio in tqdm(x):\n",
        "#     features_list.append(preprocess_function(audio))\n",
        "\n",
        "# import tensorflow as tf\n",
        "# X = tf.keras.utils.pad_sequences(features_list, padding='post', maxlen=4000)\n",
        "\n",
        "# X = X.reshape(-1, 1, 26, 4000)\n",
        "\n",
        "# np.save(\"train\", X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hz5tXg8pmrUC"
      },
      "outputs": [],
      "source": [
        "# Загрзка предпросчитанных (15-20 минут долго ждать, поэтому лучше так)\n",
        "X = np.load('train.npy').astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Нормализация данных по лейблам ~50/50\n",
        "diff = len(y) - sum(y) - sum(y)\n",
        "\n",
        "indexes = []\n",
        "\n",
        "for ind, i in enumerate(y):\n",
        "    if i == 0:\n",
        "        diff -= 1\n",
        "        indexes.append(ind)\n",
        "        if diff == 0:\n",
        "            break\n",
        "X = np.delete(X, indexes, axis=0)\n",
        "y = np.delete(y, indexes, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Проверка размерностей\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QAEvqA1-1hg",
        "outputId": "286d686e-5099-4fbc-ad79-0b9ff27c454b"
      },
      "outputs": [],
      "source": [
        "# Разделение на train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=13)\n",
        "\n",
        "print('Относительное количество положительный записей:')\n",
        "print(f'Вся выборка: {sum(y) / len(y)}')\n",
        "print(f'Обучающая выборка: {sum(y_train) / len(y_train)}')\n",
        "print(f'Валидационная выборка: {sum(y_test) / len(y_test)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Заготовки\n",
        "# resource: https://github.com/ashishpatel26/Vision-Transformer-Keras-Tensorflow-Pytorch-Examples/blob/main/Vision_Transformer_with_tf2.ipynb\n",
        "\n",
        "def gelu(x):\n",
        "    \"\"\"Gaussian Error Linear Unit.\n",
        "    This is a smoother version of the RELU.\n",
        "    Original paper: https://arxiv.org/abs/1606.08415\n",
        "    Args:\n",
        "        x: float Tensor to perform activation.\n",
        "    Returns:\n",
        "        `x` with the GELU activation applied.\n",
        "    \"\"\"\n",
        "    cdf = 0.5 * (1.0 + tf.tanh(\n",
        "        (math.sqrt(2 / math.pi) * (x + 0.044715 * tf.pow(x, 3)))))\n",
        "    return x * cdf\n",
        "\n",
        "\n",
        "def get_activation(identifier):\n",
        "    \"\"\"Maps a identifier to a Python function, e.g., \"relu\" => `tf.nn.relu`.\n",
        "    It checks string first and if it is one of customized activation not in TF,\n",
        "    the corresponding activation will be returned. For non-customized activation\n",
        "    names and callable identifiers, always fallback to tf.keras.activations.get.\n",
        "    Args:\n",
        "        identifier: String name of the activation function or callable.\n",
        "    Returns:\n",
        "        A Python function corresponding to the activation function.\n",
        "    \"\"\"\n",
        "    if isinstance(identifier, six.string_types):\n",
        "        name_to_fn = {\"gelu\": gelu}\n",
        "        identifier = str(identifier).lower()\n",
        "        if identifier in name_to_fn:\n",
        "            return tf.keras.activations.get(name_to_fn[identifier])\n",
        "    return tf.keras.activations.get(identifier)\n",
        "\n",
        "\n",
        "class Residual(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.fn(x) + x\n",
        "\n",
        "\n",
        "class PreNorm(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.fn = fn\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.fn(self.norm(x))\n",
        "\n",
        "\n",
        "class FeedForward(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.net = models.Sequential([layers.Dense(hidden_dim, activation=get_activation('gelu')),\n",
        "                                        layers.Dense(dim)])\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Attention(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, dim, heads = 8):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = dim ** -0.5\n",
        "\n",
        "        self.to_qkv = layers.Dense(dim * 3, use_bias=False)\n",
        "        self.to_out = layers.Dense(dim)\n",
        "\n",
        "        self.rearrange_qkv = Rearrange('b n (qkv h d) -> qkv b h n d', qkv = 3, h = self.heads)\n",
        "        self.rearrange_out = Rearrange('b h n d -> b n (h d)')\n",
        "\n",
        "    def call(self, x):\n",
        "        qkv = self.to_qkv(x)\n",
        "        qkv = self.rearrange_qkv(qkv)\n",
        "        q = qkv[0]\n",
        "        k = qkv[1]\n",
        "        v = qkv[2]\n",
        "\n",
        "        dots = tf.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
        "        attn = tf.nn.softmax(dots,axis=-1)\n",
        "\n",
        "        out = tf.einsum('bhij,bhjd->bhid', attn, v)\n",
        "        out = self.rearrange_out(out)\n",
        "        out =  self.to_out(out)\n",
        "        return out\n",
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, dim, depth, heads, mlp_dim):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        for _ in range(depth):\n",
        "            layers.extend([\n",
        "                Residual(PreNorm(dim, Attention(dim, heads = heads))),\n",
        "                Residual(PreNorm(dim, FeedForward(dim, mlp_dim)))\n",
        "            ])\n",
        "        self.net = tf.keras.Sequential(layers)\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnXvQjvnkMA2"
      },
      "outputs": [],
      "source": [
        "# Класс модели\n",
        "class ViTButForAIIJC(tf.keras.Model):\n",
        "    def __init__(self, *, image_size: tuple[int, int], patch_size: tuple[int, int], num_classes: int,\n",
        "                 dim: int, depth: int, heads: int, mlp_dim: int, channels: int):\n",
        "        \"\"\"Visual Transformer model for non-square images\n",
        "\n",
        "        Args:\n",
        "            image_size (tuple[int, int]): input vector sizes\n",
        "            patch_size (tuple[int, int]): path sizes\n",
        "            num_classes (int): number of classes and output shape\n",
        "            dim (int): embedding dims\n",
        "            depth (int): depth of transformer itself\n",
        "            heads (int): number of transforomer heads\n",
        "            mlp_dim (int): number of neurons in classification nn\n",
        "            channels (int): number channels in input\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        assert image_size[0] % patch_size[0] == 0 and image_size[1] % patch_size[1] == 0, 'image dimensions must be divisible by the patch size'\n",
        "        num_patches = (image_size[0] // patch_size[0]) * (image_size[1] // patch_size[1])\n",
        "        patch_dim = channels * patch_size[0] * patch_size[1]\n",
        "\n",
        "        self.patch_size = patch_size\n",
        "        self.dim = dim\n",
        "        self.pos_embedding = self.add_weight(name=\"position_embeddings\",\n",
        "                                             shape=[num_patches + 1, dim],\n",
        "                                             initializer=tf.keras.initializers.RandomNormal(),\n",
        "                                             dtype=tf.float32)\n",
        "        self.patch_to_embedding = layers.Dense(dim)\n",
        "        self.cls_token = self.add_weight(name=\"cls_token\",\n",
        "                                         shape=[1,\n",
        "                                                1,\n",
        "                                                dim],\n",
        "                                         initializer=tf.keras.initializers.RandomNormal(),\n",
        "                                         dtype=tf.float32)\n",
        "\n",
        "        self.rearrange = Rearrange('b c (w p1) (l p2) -> b (w l) (p1 p2 c)', p1=patch_size[0], p2=patch_size[1])\n",
        "\n",
        "        self.transformer = Transformer(dim, depth, heads, mlp_dim)\n",
        "\n",
        "        self.to_cls_token = tf.identity\n",
        "\n",
        "        self.mlp_head = models.Sequential([\n",
        "            layers.Dense(mlp_dim, activation=get_activation('gelu')),\n",
        "            layers.Dense(num_classes, activation=('sigmoid' if num_classes == 1 else 'softmax'))\n",
        "        ])\n",
        "        self.mlp_head.name = 'classification_head'\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, fbank):\n",
        "        shapes = tf.shape(fbank)\n",
        "\n",
        "        x = self.rearrange(fbank)\n",
        "\n",
        "        x = self.patch_to_embedding(x)\n",
        "\n",
        "        cls_tokens = tf.broadcast_to(self.cls_token,(shapes[0],1,self.dim))\n",
        "\n",
        "        x = tf.concat((cls_tokens, x), axis=1)\n",
        "        x += self.pos_embedding\n",
        "        x = self.transformer(x)\n",
        "\n",
        "        x = self.to_cls_token(x[:, 0])\n",
        "        return self.mlp_head(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Проверка шейпов (читай)\n",
        "X[0].shape # (channels, image_size[0], image_size[1])\n",
        "# | | |\n",
        "# V V V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Конфиг для модели\n",
        "model = ViTButForAIIJC(\n",
        "    # Лучше не менять\n",
        "    image_size=(26, 4000),\n",
        "    patch_size=(2, 100),\n",
        "    num_classes=1,\n",
        "    channels=1,\n",
        "\n",
        "    # Можно крутить\n",
        "    dim=256,\n",
        "    depth=4,\n",
        "    heads=4,\n",
        "    mlp_dim=1024,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9n0HMQXkMA3"
      },
      "outputs": [],
      "source": [
        "# Конфиг для обучения\n",
        "epochs = 50\n",
        "batch_size=8\n",
        "optim = 'adam' # adam/sgd\n",
        "lr = 2e-5\n",
        "momentum = 0.8 # sgd only\n",
        "# early stop\n",
        "es_delta = 1e-3\n",
        "es_patience = 20\n",
        "# reducing lr\n",
        "red_lr_factor = 0.5\n",
        "red_lr_patience = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Применяем конфиг\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "if optim == 'adam':\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "else:\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=lr, momentum=momentum)\n",
        "\n",
        "custom_callbacks = [\n",
        "    callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        min_delta=es_delta,\n",
        "        patience=es_patience,\n",
        "        verbose=1,\n",
        "        mode='auto',\n",
        "        baseline=None,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    callbacks.ModelCheckpoint(\n",
        "        filepath='./saves/rnn_mfcc.weights.h5',\n",
        "        monitor='val_f1_score',\n",
        "        mode='max',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=red_lr_factor, patience=red_lr_patience, verbose=1)\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_fn,\n",
        "    metrics=[\n",
        "        'accuracy', \n",
        "        tf.keras.metrics.F1Score(average='macro', threshold=0.5),\n",
        "        tf.keras.metrics.Precision(),  # correct 1 / all predicted as 1\n",
        "        tf.keras.metrics.Recall()  # correct 1 / all 1\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Лес гоу 🥵\n",
        "hist = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=epochs,\n",
        "    callbacks=custom_callbacks,\n",
        "    verbose=1,\n",
        "    validation_data=(X_test, y_test),\n",
        "    batch_size=batch_size\n",
        "#    class_weight=class_weight  # У нас 50/50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "CxyoeEVykMA4",
        "outputId": "0cb1373a-4723-4865-bb0e-169d587d85f4"
      },
      "outputs": [],
      "source": [
        "# Как прошли уроки?\n",
        "hist_df = pd.DataFrame(hist.history).drop(columns=['learning_rate'])\n",
        "hist_df.plot(figsize=(8,5))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "UIz-dOrs-1hi",
        "outputId": "453d4698-9bd4-4c44-c79f-298cb703b679"
      },
      "outputs": [],
      "source": [
        "# Саммари\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkmInpbvpqgO"
      },
      "outputs": [],
      "source": [
        "# # Загрзка весов (можно закоментить, если видно, что лучшая глупая - много одинаковых классов)\n",
        "# model.load_weights('./saves/rnn_mfcc.weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzcc8IRg-1hj",
        "outputId": "e0fc298c-b822-4123-8ef7-fcc72b129d71"
      },
      "outputs": [],
      "source": [
        "# Финальная оценочка\n",
        "print('На валидационной выборке')\n",
        "model.evaluate(X_test, y_test, return_dict=True)\n",
        "print('На всех данных')\n",
        "model.evaluate(X, y, return_dict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQir61AI-1hj"
      },
      "source": [
        "## Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gVa6Mi7-1hk"
      },
      "outputs": [],
      "source": [
        "# task = pd.read_csv(TASK_FILENAME, header=None, names=['audio', 'label'])\n",
        "# task['audio'] = TASK_DATA_PATH + \"/\" + task['audio']\n",
        "\n",
        "# task_x = task['audio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq9teWIi-1hl"
      },
      "outputs": [],
      "source": [
        "# task_features_list = []\n",
        "\n",
        "# for audio in tqdm(task_x):\n",
        "#     task_features_list.append(preprocess_function(audio))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# task_X = tf.keras.utils.pad_sequences(task_features_list, padding='post', maxlen=4000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgODkMfdetCJ"
      },
      "outputs": [],
      "source": [
        "# np.save(\"test\", task_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFPaNXg1pgOu"
      },
      "outputs": [],
      "source": [
        "task_X = np.load('test.npy').astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gTzlvE_-1hl",
        "outputId": "b47d915d-93c4-4c3c-df9a-214da32885fb"
      },
      "outputs": [],
      "source": [
        "task_y = model.predict(task_X)\n",
        "task_y = np.round(task_y).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FLq71PjUtUV",
        "outputId": "a19b4c18-1f89-48cd-f7b8-5c31ad0470d3"
      },
      "outputs": [],
      "source": [
        "np.sum(task_y) / len(task_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3oaIdY7-1hl"
      },
      "outputs": [],
      "source": [
        "submit = pd.read_csv(TASK_FILENAME, header=None, names=['audio', 'label'])\n",
        "submit['label'] = task_y\n",
        "submit.to_csv('submit.csv', header=False, index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
